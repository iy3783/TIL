1. 하둡 파일 시스템 : 빅데이터 처리용 파일 시스템
자바 기반의 오픈소스 Framework , 빅데이터 처리를 위해 분산 컴퓨팅 환경
요구된다. 
HDFS(하둡  분산 파일 시스템): 아파치 하둡 프로젝트의 분산 파일 시스템이었다.
아파치 너치라는 웹검색 엔진 프로젝트를 위해 만들어졌었다. 
확장가능한 웹 크롤러 소프트 웨어
웹 방대한 데이터 처리 위해 구글 발간 구글 파일 시스템 논문과 맵 리듀스 논문을 기초로
HDFS 만듬

- data 유실 방지
- data 저장 /조회 스트리밍 방식으로 접근
- 한번 저장한 데이터는 수정 불가 , Data 무결성 유지,write는 안됨
- data 이동,삭제,복사는 가능

2.하둡 클러스터의 이해 
-클라이언트 머신 
-마스터 노드 : 많은 양의 데이터를 하둡에 저장, 맵 리듀스(병렬 계산) 수행하는 클러스터
job tracker : 맵 리듀스 , 분산 처리 데이터 프로세싱
namenode : 분산 데이터 저장
secondary namenode
-슬레이브 노드 : 세부적인 일들. 서로간의 통신 가능하고 마스터노드의 지시를 받음
데이터노드 -네임노드
테스크트랙커 - 잡 트랙커8

3. 
-네임노드 : 파일과 디렉토리에 대한 메타데이터 정보를 저장 
(블록들이 저장되는 디렉토리 이름, 파일 이름)
-데이터 노드 : 요청한 파일 읽거나 저장,네임노드의 지시에 따라 블록을 생성 ,삭제,복제
:파일 저장시 블록단위로 저장 ;HDFS 기본 블록 사이즈 64MB설정
우린 맨날 128MB씀

4.HDFS 구조

client <--> nameNode   : 클라이언트가 하나의 네임노드와 연결  -> secondary namenode
		        네임노드는 여러 데이터노드와 연결         와도 연결된다.
		+
datanode datanode datanode datanode

: 데이터 노드들이 네임노드에게 주기적 리포트 보냄
(block report) 
-namenode == file system name space

5. 
data replication (복제)
 : client는 128MB 블록단위로 분할
같은 블록을 클러스터에 있는 세곳의 노드에 복제
동일 블록으로 분할되기 때문에 병렬처리가 가능하다.
=> 하둡에서는 데이터 복제 기본값은 3으로 설정


6. 
랙인식 : 데이터 복제시 랙을 선택하는 것은 데이터의 손실을 방지하는 것과 
네트워크의 성능을 높이는 측면에서 중요함, 랙번호를 정의하므로써 위치 선택가능
=> 데이터 복제했는데 같은 랙이면 안됨 (같이 고장남)
=> 데이터 복제본이 클러스터 어디 위치에 있어야 하는지 결정을 잘해야함
=> 이런 결정을 네임노드가 함

네트워크 성능과 가용성을 고려한 중요한 규칙
=> 하나의 랙 안에 두개의 복사본을 저장하고 다른 랙에 나머지 복사본을 저장하는
규칙을 적용

나눠져 있는 데이터 노드들은 서로 응답하면서 준비 완료를 알려야 한다.=> 다
완료되어야 클라이언트에 최종적으로 응답한다.


7. HDFS write pipeline => 그냥 tcp 연결을  pipeline처럼 쓴다.


